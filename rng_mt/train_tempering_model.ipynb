{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 23:56:21.066674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 23:56:21.076509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 23:56:21.077133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_COUNT = 5000000\n",
    "TEST_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_OUTPUT_FILENAME=\"mersenne_twist_xorshifter.txt\"\n",
    "df = np.genfromtxt(RNG_OUTPUT_FILENAME,delimiter=', ',dtype='uint64', max_rows=IMPORT_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates how many bits are in the output.\n",
    "BIT_WIDTH=np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits = np.concatenate(((df[:, 0][:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int), (df[:, 1][:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data frames\n",
    "indicies = np.arange(df_as_bits.shape[0],dtype='uint64')\n",
    "np.random.shuffle(indicies)\n",
    "df_as_bits=df_as_bits[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into inputs and outputs\n",
    "y = df_as_bits[:,32:]\n",
    "X = df_as_bits[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data\n",
    "X_train = X[TEST_COUNT:]\n",
    "X_test = X[:TEST_COUNT]\n",
    "y_train = y[TEST_COUNT:]\n",
    "y_test = y[:TEST_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    LOSS=\"binary_crossentropy\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(640, activation='relu',input_shape=[X.shape[1]] ))\n",
    "    model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "    \n",
    "    opt = keras.optimizers.Nadam(\n",
    "        learning_rate=hp.Float(\"learning_rate\", 10**(-5), 10**(-2),sampling=\"log\"),\n",
    "        epsilon=hp.Float(\"epsilon\",1e-7,1e-4,sampling=\"log\"),\n",
    "        beta_1=hp.Float(\"beta_1\",.8,.99999,sampling=\"reverse_log\"),\n",
    "        beta_2=hp.Float(\"beta_2\",.8,.99999,sampling=\"reverse_log\"),\n",
    "        )\n",
    "    model.compile(optimizer=opt, loss=LOSS,metrics=['binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define callback functions\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy', min_delta=.001, patience=10, verbose=0, mode='auto', restore_best_weights=False\n",
    ")\n",
    "\n",
    "log_dir = \"tmp/hyperparameters_tempering/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short set from the training for hyper parameter tuning\n",
    "X_train_short= X_train[:1000000]\n",
    "y_train_short= y_train[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 02m 18s]\n",
      "val_binary_accuracy: 0.7568156123161316\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.9998593926429749\n",
      "Total elapsed time: 00h 43m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in ./tmp/tempering\n",
      "Showing 10 best trials\n",
      "Objective(name='val_binary_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9998593926429749\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8810412165270334\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9998406171798706\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.9031492462258401\n",
      "beta_2: 0.9021489810373363\n",
      "Score: 0.9995343685150146\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8538783427826274\n",
      "beta_2: 0.8512431397642117\n",
      "Score: 0.9845343828201294\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 3.1636418824271017e-06\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9842093586921692\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0008093262370610817\n",
      "epsilon: 3.824434879437115e-06\n",
      "beta_1: 0.9757233918257775\n",
      "beta_2: 0.9680146121732406\n",
      "Score: 0.982450008392334\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 3.0724633355222893e-06\n",
      "beta_1: 0.9057817292825319\n",
      "beta_2: 0.9111378117498075\n",
      "Score: 0.9696124792098999\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 9.154130986646072e-06\n",
      "beta_1: 0.8745973005782165\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9691406488418579\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.9073176652694618\n",
      "Score: 0.9689781069755554\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0014677818091307047\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8798331909235418\n",
      "beta_2: 0.9666355975831159\n",
      "Score: 0.9685187339782715\n",
      "CPU times: user 1h 12min 33s, sys: 13min 58s, total: 1h 26min 31s\n",
      "Wall time: 43min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning the hyper parameters\n",
    "tuner = kt.tuners.bayesian.BayesianOptimization(build_model,'val_binary_accuracy',25,project_name=\"tmp/tempering\", seed=myrand)\n",
    "\n",
    "while tuner.remaining_trials>0:\n",
    "    try:\n",
    "        tuner.search(X_train_short, y_train_short,batch_size=2048, epochs=100, validation_data=(X_test,y_test),callbacks=[stopEarly,tensorboard_callback])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 640)               21120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                20512     \n",
      "=================================================================\n",
      "Total params: 41,632\n",
      "Trainable params: 41,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'epsilon': 0.0001,\n",
       " 'beta_1': 0.8000000000000002,\n",
       " 'beta_2': 0.8000000000000002}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "# use the best model for training\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X = X_train, Y=y_train, epochs=100, batch_size=2048,verbose=1, log_dir = \"tmp/dense_model/\"):\n",
    "    log_dir += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)\n",
    "    model.fit(X, Y, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size,callbacks=[tensorboard_callback],verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.4978 - binary_accuracy: 0.6624 - val_loss: 0.3570 - val_binary_accuracy: 0.7718\n",
      "Epoch 2/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.2782 - binary_accuracy: 0.8192 - val_loss: 0.2282 - val_binary_accuracy: 0.8524\n",
      "Epoch 3/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.1687 - binary_accuracy: 0.9019 - val_loss: 0.1136 - val_binary_accuracy: 0.9372\n",
      "Epoch 4/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0890 - binary_accuracy: 0.9470 - val_loss: 0.0756 - val_binary_accuracy: 0.9517\n",
      "Epoch 5/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0673 - binary_accuracy: 0.9567 - val_loss: 0.0559 - val_binary_accuracy: 0.9656\n",
      "Epoch 6/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0514 - binary_accuracy: 0.9670 - val_loss: 0.0483 - val_binary_accuracy: 0.9677\n",
      "Epoch 7/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0468 - binary_accuracy: 0.9682 - val_loss: 0.0466 - val_binary_accuracy: 0.9682\n",
      "Epoch 8/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0453 - binary_accuracy: 0.9686 - val_loss: 0.0443 - val_binary_accuracy: 0.9687\n",
      "Epoch 9/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0447 - binary_accuracy: 0.9687 - val_loss: 0.0442 - val_binary_accuracy: 0.9686\n",
      "Epoch 10/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0445 - binary_accuracy: 0.9687 - val_loss: 0.0449 - val_binary_accuracy: 0.9682\n",
      "Epoch 11/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0443 - binary_accuracy: 0.9689 - val_loss: 0.0438 - val_binary_accuracy: 0.9696\n",
      "Epoch 12/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0388 - binary_accuracy: 0.9748 - val_loss: 0.0297 - val_binary_accuracy: 0.9813\n",
      "Epoch 13/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0267 - binary_accuracy: 0.9829 - val_loss: 0.0243 - val_binary_accuracy: 0.9846\n",
      "Epoch 14/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0199 - binary_accuracy: 0.9889 - val_loss: 0.0158 - val_binary_accuracy: 0.9903\n",
      "Epoch 15/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9951 - val_loss: 0.0074 - val_binary_accuracy: 0.9979\n",
      "Epoch 16/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0058 - binary_accuracy: 0.9984 - val_loss: 0.0028 - val_binary_accuracy: 0.9996\n",
      "Epoch 17/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0026 - binary_accuracy: 0.9995 - val_loss: 0.0018 - val_binary_accuracy: 0.9996\n",
      "Epoch 18/30\n",
      "2437/2437 [==============================] - 6s 3ms/step - loss: 0.0016 - binary_accuracy: 0.9997 - val_loss: 0.0010 - val_binary_accuracy: 0.9998\n",
      "Epoch 19/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0011 - binary_accuracy: 0.9998 - val_loss: 9.1433e-04 - val_binary_accuracy: 0.9999\n",
      "Epoch 20/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 8.3665e-04 - binary_accuracy: 0.9998 - val_loss: 5.3904e-04 - val_binary_accuracy: 0.9999\n",
      "Epoch 21/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 6.3382e-04 - binary_accuracy: 0.9999 - val_loss: 5.8941e-04 - val_binary_accuracy: 0.9999\n",
      "Epoch 22/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 4.8124e-04 - binary_accuracy: 0.9999 - val_loss: 2.9243e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 3.4575e-04 - binary_accuracy: 1.0000 - val_loss: 2.1832e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.4041e-04 - binary_accuracy: 1.0000 - val_loss: 1.7322e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.6998e-04 - binary_accuracy: 1.0000 - val_loss: 1.2867e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.3011e-04 - binary_accuracy: 1.0000 - val_loss: 1.0538e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.0135e-04 - binary_accuracy: 1.0000 - val_loss: 9.5264e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 8.2453e-05 - binary_accuracy: 1.0000 - val_loss: 8.7882e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 7.0708e-05 - binary_accuracy: 1.0000 - val_loss: 7.8415e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 6.2305e-05 - binary_accuracy: 1.0000 - val_loss: 6.3016e-05 - val_binary_accuracy: 1.0000\n",
      "CPU times: user 5min 47s, sys: 1min 8s, total: 6min 56s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_model_trained = train_model(model, epochs=30,log_dir = \"tmp/mt_tempering/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 6.3016e-05 - binary_accuracy: 1.0000\n",
      "test loss: 0.000063, test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mt_tempering_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
