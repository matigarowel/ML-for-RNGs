{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 17:57:10.210691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 17:57:10.219653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 17:57:10.220284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_COUNT = 5000000\n",
    "TEST_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_OUTPUT_FILENAME=\"mersenne_twist_xorshifter.txt\"\n",
    "df = np.genfromtxt(RNG_OUTPUT_FILENAME,delimiter=', ',dtype='uint64', max_rows=IMPORT_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates how many bits are in the output.\n",
    "BIT_WIDTH=np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits = np.concatenate(((df[:, 0][:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int), (df[:, 1][:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into inputs and outputs\n",
    "y = df_as_bits[:,32:]\n",
    "X = df_as_bits[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data\n",
    "X_train = X[TEST_COUNT:]\n",
    "X_test = X[:TEST_COUNT]\n",
    "y_train = y[TEST_COUNT:]\n",
    "y_test = y[:TEST_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    LOSS=\"binary_crossentropy\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(640, activation='relu',input_shape=[X.shape[1]] ))\n",
    "    model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "    \n",
    "    opt = keras.optimizers.Nadam(\n",
    "        learning_rate=hp.Float(\"learning_rate\", 10**(-5), 10**(-2),sampling=\"log\"),\n",
    "        epsilon=hp.Float(\"epsilon\",1e-7,1e-4,sampling=\"log\"),\n",
    "        beta_1=hp.Float(\"beta_1\",.8,.99999,sampling=\"reverse_log\"),\n",
    "        beta_2=hp.Float(\"beta_2\",.8,.99999,sampling=\"reverse_log\"),\n",
    "        )\n",
    "    model.compile(optimizer=opt, loss=LOSS,metrics=['binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define callback functions\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy', min_delta=.001, patience=10, verbose=0, mode='auto', restore_best_weights=False\n",
    ")\n",
    "\n",
    "log_dir = \"hyperparameters_tempering/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short set from the training for hyper parameter tuning\n",
    "X_train_short= X_train[:1000000]\n",
    "y_train_short= y_train[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 01m 39s]\n",
      "val_binary_accuracy: 0.9998624920845032\n",
      "\n",
      "Best val_binary_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 42m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in ./tempering\n",
      "Showing 10 best trials\n",
      "Objective(name='val_binary_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004607011470645479\n",
      "epsilon: 2.2025932985636275e-06\n",
      "beta_1: 0.8458740913046512\n",
      "beta_2: 0.8771775194185945\n",
      "Score: 1.0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.900895705294404\n",
      "beta_2: 0.8527594898508055\n",
      "Score: 0.9999750256538391\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 5.735042637265392e-06\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9999656081199646\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.9235253080389627\n",
      "beta_2: 0.9116685672937969\n",
      "Score: 0.9998624920845032\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.8000000000000002\n",
      "Score: 0.9998124837875366\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0010561449601734995\n",
      "epsilon: 1e-07\n",
      "beta_1: 0.8000000000000002\n",
      "beta_2: 0.8982730519229354\n",
      "Score: 0.9901999831199646\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.006180115184928233\n",
      "epsilon: 1e-07\n",
      "beta_1: 0.8548633468865048\n",
      "beta_2: 0.9176975434174831\n",
      "Score: 0.9844281077384949\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0011622683857788686\n",
      "epsilon: 1e-07\n",
      "beta_1: 0.9091936107672802\n",
      "beta_2: 0.9139420593035691\n",
      "Score: 0.9842625260353088\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0010212603453559122\n",
      "epsilon: 3.389934961279716e-07\n",
      "beta_1: 0.8094728692318156\n",
      "beta_2: 0.9459153759664042\n",
      "Score: 0.9834312796592712\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0011468592776939966\n",
      "epsilon: 4.6072763548230333e-07\n",
      "beta_1: 0.8578348597191162\n",
      "beta_2: 0.9077810247708897\n",
      "Score: 0.9690874814987183\n",
      "CPU times: user 1h 10min 46s, sys: 13min 38s, total: 1h 24min 24s\n",
      "Wall time: 42min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning the hyper parameters\n",
    "tuner = kt.tuners.bayesian.BayesianOptimization(build_model,'val_binary_accuracy',25,project_name=\"tempering\")\n",
    "\n",
    "while tuner.remaining_trials>0:\n",
    "    try:\n",
    "        tuner.search(X_train_short, y_train_short,batch_size=2048, epochs=100, validation_data=(X_test,y_test),callbacks=[stopEarly,tensorboard_callback])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 640)               21120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                20512     \n",
      "=================================================================\n",
      "Total params: 41,632\n",
      "Trainable params: 41,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.004607011470645479,\n",
       " 'epsilon': 2.2025932985636275e-06,\n",
       " 'beta_1': 0.8458740913046512,\n",
       " 'beta_2': 0.8771775194185945}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "# use the best model for training\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X = X_train, Y=y_train, epochs=100, batch_size=2048,verbose=1, log_dir = \"dense_model/\"):\n",
    "    log_dir += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)\n",
    "    model.fit(X, Y, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size,callbacks=[tensorboard_callback],verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2437/2437 [==============================] - 8s 3ms/step - loss: 0.4637 - binary_accuracy: 0.6884 - val_loss: 0.3136 - val_binary_accuracy: 0.7971\n",
      "Epoch 2/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.2491 - binary_accuracy: 0.8376 - val_loss: 0.2011 - val_binary_accuracy: 0.8706\n",
      "Epoch 3/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.1660 - binary_accuracy: 0.8942 - val_loss: 0.1328 - val_binary_accuracy: 0.9174\n",
      "Epoch 4/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.1044 - binary_accuracy: 0.9366 - val_loss: 0.0801 - val_binary_accuracy: 0.9502\n",
      "Epoch 5/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0713 - binary_accuracy: 0.9522 - val_loss: 0.0674 - val_binary_accuracy: 0.9532\n",
      "Epoch 6/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0650 - binary_accuracy: 0.9553 - val_loss: 0.0583 - val_binary_accuracy: 0.9629\n",
      "Epoch 7/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0512 - binary_accuracy: 0.9666 - val_loss: 0.0464 - val_binary_accuracy: 0.9685\n",
      "Epoch 8/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0452 - binary_accuracy: 0.9686 - val_loss: 0.0443 - val_binary_accuracy: 0.9686\n",
      "Epoch 9/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0437 - binary_accuracy: 0.9695 - val_loss: 0.0408 - val_binary_accuracy: 0.9741\n",
      "Epoch 10/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0308 - binary_accuracy: 0.9813 - val_loss: 0.0246 - val_binary_accuracy: 0.9841\n",
      "Epoch 11/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0229 - binary_accuracy: 0.9843 - val_loss: 0.0222 - val_binary_accuracy: 0.9846\n",
      "Epoch 12/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0169 - binary_accuracy: 0.9910 - val_loss: 0.0112 - val_binary_accuracy: 0.9955\n",
      "Epoch 13/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0075 - binary_accuracy: 0.9974 - val_loss: 0.0048 - val_binary_accuracy: 0.9986\n",
      "Epoch 14/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0033 - binary_accuracy: 0.9991 - val_loss: 0.0022 - val_binary_accuracy: 0.9995\n",
      "Epoch 15/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 7.2984e-04 - val_binary_accuracy: 0.9999\n",
      "Epoch 16/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 5.3739e-04 - binary_accuracy: 1.0000 - val_loss: 3.7232e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.5865e-04 - binary_accuracy: 1.0000 - val_loss: 1.4886e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.3797e-04 - binary_accuracy: 1.0000 - val_loss: 8.0091e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 7.7477e-05 - binary_accuracy: 1.0000 - val_loss: 4.5935e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 4.5415e-05 - binary_accuracy: 1.0000 - val_loss: 3.0235e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.6177e-05 - binary_accuracy: 1.0000 - val_loss: 1.6612e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.4032e-05 - binary_accuracy: 1.0000 - val_loss: 9.2470e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 8.4271e-06 - binary_accuracy: 1.0000 - val_loss: 6.2826e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 5.6879e-06 - binary_accuracy: 1.0000 - val_loss: 4.7331e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 4.2299e-06 - binary_accuracy: 1.0000 - val_loss: 3.6287e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 3.3536e-06 - binary_accuracy: 1.0000 - val_loss: 2.9515e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.7812e-06 - binary_accuracy: 1.0000 - val_loss: 2.4843e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.3820e-06 - binary_accuracy: 1.0000 - val_loss: 2.2065e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 2.0836e-06 - binary_accuracy: 1.0000 - val_loss: 1.9170e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2437/2437 [==============================] - 7s 3ms/step - loss: 1.8533e-06 - binary_accuracy: 1.0000 - val_loss: 1.6763e-06 - val_binary_accuracy: 1.0000\n",
      "CPU times: user 6min, sys: 1min 11s, total: 7min 11s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_model_trained = train_model(model, epochs=30,log_dir = \"tempering/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 1.6763e-06 - binary_accuracy: 1.0000\n",
      "test loss: 0.000002, test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mt_tempering_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
